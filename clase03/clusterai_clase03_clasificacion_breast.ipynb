{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "__Universidad Tecnológica Nacional, Buenos Aires__<br/>\n",
    "__Ingeniería Industrial__<br/>\n",
    "__Cátedra de Ciencia de Datos - Curso I5521__<br/>\n",
    "__Elaborado por: Martin Palazzo__\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación en dataset Breast Cancer Wisconsin\n",
    "En el siguiente notebook aplicaremos distintos clasificadores sobre un popular dataset de cancer de mamas. Analizaremos distintas formas de entrenar los modelos y utilizaremos distintos enfoques para evaluar los resultados y seleccionar los hiper-parametros.\n",
    "\n",
    "#### **Contexto del dataset**\n",
    "Supongamos que tenemos un set de datos de $n=569$ muestras de tumores, cada una caracterizada por 32 variables de las cuales $d = 31$ de ellas son variables observadas en cada tumor y almacenadas en cada registro. La variable restante $y$ es el diagnostico Benigno (B) o Maligno (M) etiquetado por el especialista en patología. <br>\n",
    "<br>\n",
    "Vamos a querer aprender una regla de decisión utilizando métodos de Machine Learning que decida si un tumor es Maligno o Benigno unicamente observando las 31 variables.<br>\n",
    "<br>\n",
    "Es decir que aprenderemos una funcion $f(x) = y$ donde $x$ son las variables independientes que caracterizan a cada tumor (features), la función $f(x)$ será utilizada para decidir la categoría $y$ usada para representar la etiqueta del tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar las librerias que venimos usando siempre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerías necesarias para trabajar.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerias de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import (\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos dataset de Wisconsin Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos el dataset con Pandas\n",
    "# el parámetro index_col indica que la primer columna (la 0) contiene un indicador único por cáda registro\n",
    "# index_col no será parte del dataset, solo cumplirá la función de índice.\n",
    "breast = pd.read_csv('dataset_breast_wisconsin.csv', delimiter=';', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el dataset con Pandas. Observamos que en la columna \"diagnosis\" se encuentra si el tumor es benigno o maligno. El resto de las columnas refiere a distintas features del tumor. Ver que la primer columna es el ID del paciente, esta información no nos interesa!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos el tamaño del dataset\n",
    "breast.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a revisar si existen valores nulos en la tabla que contiene los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el comando .isnull() de Pandas revisará cada columna para ver si existen o no valores nulos.\n",
    "breast.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separo mi variable independiente**: Vamos a guardar en una matriz llamada $x$ las features asociadas a cada muestra. Esta matriz contendra datos que utilizaremos para predecir la cateogira (Maligno-Benigno) de un tumor. Las filas de la matriz representarán cada tumor mientras que las columnas representarán las variables/features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente vamos a crear \"x\" solamente utilizando las features desde la columna 2 a la 4. Recordemos que en el dataset la columna \"diagnosis\" no es una variable independiente y solo representaa las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta primera instancia vamos a usar las features 10, 11 , 12 y 13.Para ello realizaremos un filtrado de pandas con .iloc\n",
    "# en un \"slice\" el último número no cuenta.\n",
    "x = breast.iloc[:,10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con .head() observamos el dataframe resultante\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizamos un heatmap sobre la matriz X resultante \n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un Pairplot vamos a visualizar como se relacionan par-a-par las variables seleccionadas a lo largo de todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.pairplot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a calcular la correlacion lineal de pearson para las features de nuestro dataset\n",
    "corr_matrix = x.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ademas vamos a visualizar la matriz de correlacion\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap( corr_matrix ,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separo mi variable dependiente Y**: Ahora procederemos a crear el vector de etiquetas con las variables dependientes. Ver que las etiquetas se encuentran en la 1er columna (es decir la columna 0) del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con .iloc filtramos la primer columna del dataframe para obtener las etiquetas\n",
    "y = breast.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las etiquetas/labels estan presentadas como categorias y deberiamos pasarlas a una representacion numerica\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformo mi variable dependiente Y en numerica**: previamente estaba como string.\n",
    "Vemos que las etiquetas se encuentran asignadas con M y B. Para transformarlas a numéricas utilizaremos el \"LabelEncoder\" de sklearn y las pasaremos a numeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# \"le\" es el label encoder que transforma las etiquetas de string a INT.\n",
    "le = preprocessing.LabelEncoder()\n",
    "# sobre-escribo el vector \"y\" con las etiquetas numericas obtenidas del label encoder\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora las etiquetas son numericas\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separo mi dataset en Train y Test**:\n",
    "Con la funcion \"train_test_split\" de sklearn separaremos nuestro dataset (tanto x como y) en dos sets de entrenamiento y prueba independiente. Podemos elegir que % de muestras esten en cada conjunto. El random_state sirve para que pueda reproducirse la \"aleatoriedad\" de division de muestras en el futuro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos xtrain, xtest, ytrain e ytest :) \n",
    "# OJO! en este caso estamos usando 95% de test para hacerla mas dificil\n",
    "# en general el test set es entre 20 y 30% \n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x.values, y, test_size=0.95, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos como queda la matriz de xtrain\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos como queda la matriz de xtest\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auto-Scaling utilizando muestras de train**: \n",
    "Queremos dejar todas las features en los mismos rangos por eso utilizaremos el standard scaler para que queden con media 0 y desvio standard 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto scaling train- set (mean = 0, std = 1)\n",
    "# ver que en la misma linea creamos el standard scaler y lo \"fiteamos\" al mismo tiempo con \"xtrain\"\n",
    "scaler = preprocessing.StandardScaler().fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain_scal tendra el dataset de train pre-procesado con el standard scaler\n",
    "xtrain_scal = scaler.transform(xtrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada feature imprimimos la media y el desvio standard obtenido. Ver que media = 0 y stdev = 1.\n",
    "print(\"media de cada feature a lo largo del dataset\")\n",
    "print(xtrain_scal.mean(axis=0))\n",
    "print(\" \")\n",
    "print(\"Desvio STD de cada feature a lo largo del dataset\")\n",
    "print(xtrain_scal.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos en que type quedo xtrain_xcal\n",
    "type(xtrain_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando el scaler \"fiteado\" o \"ajustado\" a los datos de train, aplicamos el scaler a los datos de test.\n",
    "# obtenemos \"xtest_scal\" \n",
    "xtest_scal = scaler.transform(xtest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obviamente la media y stdev de las features en test no seran 0 y 1 ya que el scaler se ajusto con train unicamente.\n",
    "print(xtest_scal.mean(axis=0))\n",
    "print(xtest_scal.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la matriz de datos de entrenamiento previo y post a estandarizacion/preprocesamiento con un mapa de calor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(16,5))\n",
    "sns.heatmap(x, ax = axs[0])\n",
    "sns.heatmap(xtrain_scal, ax = axs[1])\n",
    "sns.heatmap(xtest_scal, ax = axs[2])\n",
    "axs[0].set_title('Raw data pre-standarization')\n",
    "axs[1].set_title('Standarized train data')\n",
    "axs[2].set_title('Standarized test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la distribucion de las features con boxplots de entrenamiento previo a estandarizacion/preprocesamiento con un boxplot por cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2,figsize=(10,4))\n",
    "#plt.figure(figsize=(14,8))\n",
    "axs[0].boxplot([xtrain[:,0],xtrain[:,1],xtrain[:,2], xtrain[:,3]])\n",
    "axs[1].boxplot([xtrain_scal[:,0],xtrain_scal[:,1],xtrain_scal[:,2], xtrain_scal[:,3]])\n",
    "axs[0].set_title('Variables pre estandarizacion')\n",
    "axs[1].set_title('Variables post estandarizacion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelo con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino modelo LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino modelo LR llamado model_lr\n",
    "# (OJO! no estamos haciendo grid-search)\n",
    "model_lr = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizo un cross validation de 5 folds para ver la performance del modelo con distintas particiones de entrenamiento\n",
    "cv_results = cross_validate(model_lr, xtrain_scal, ytrain, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analizamos los resultados de cada iteracion del cross validation. \n",
    "# Este objeto indica el tiempo que tomo cada iteracion, y en \"test_score\" cuanto dio el resultado de accuracy\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estudiamos como fue el promedio de todos los accuracys a lo largo de todas las iteraciones de cross validation\n",
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajusto-entreno (fiteo) modelo a los datos de train. OJO! aca no estamos usando cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusto mi modelo a las muestras de training utilizando tanto Xtrain como Ytrain\n",
    "model_lr.fit(xtrain_scal, ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago prediccion de los datos de test (sin utilizar las etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero predicciones con mi modelo entrenado para las muestras de Test, utilizando solo Xtest\n",
    "ypred = model_lr.predict(xtest_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos en pantalla el resultado de las predicciones para cada muestra del conjunto de test\n",
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computo la exactitud de mi modelo entre las etiquetas de test reales y las asignadas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computo el accuracy (comparar ytest vs ypred)\n",
    "test_acc = accuracy_score(ytest, ypred)\n",
    "print(\"El accuracy es \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computamos el Area debajo de la curva ROC del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute and plot AUC\n",
    "yproba = model_lr.predict_proba(xtest_scal)\n",
    "fpr1, tpr1, thresholds = roc_curve(ytest.astype('int'), yproba[:,1], drop_intermediate = False)\n",
    "auc_ = auc(fpr1, tpr1)\n",
    "print(\"El AUC es = \" + str(auc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr1, tpr1, lw=2, alpha=0.7 , label = 'ROC curve', color = 'b')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='r',label='Luck', alpha=.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(False)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('ROC curve with LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion Matrix\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, index = ['Cancer', 'Control'], columns = ['Cancer', 'Control'])\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('Classification Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 01: \n",
    "- crear un nuevo set de xtrain y xtest utilizando todas las variables disponibles ya que antes solo habiamos usado un sub-conjunto de las mismas(y asi tener mejor poder de prediccion :)\n",
    "- Deberan nombrarlas con otro nombre distinto al creado anteriormente y luego comparar resultados de AUC ROC y Accuracy.\n",
    "- utilizar 70% de train y 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 02: \n",
    "- Un SVM con grid search y cross validation cv = 5 utilizando el dataset con todas las features realizado en el punto anterior. \n",
    "- Comparar resultados de clasificación entre ambos modelos.\n",
    "- determinar que parametros son los \"ganadores\" del grid search para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000], 'gamma':[0.0001,0.001, 0.01, 0.1,1, 10,100]}\n",
    "svc = svm.SVC()\n",
    "clf_svm = GridSearchCV(svc, param_grid = parameters, refit = True, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 03:\n",
    "- Entrenar un modelo de logistic regression sobre los datos del punto 01 aplicando cross validation.\n",
    "- comparar los resultados con el SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {'C':[1, 10, 100, 1000]}\n",
    "lr_model = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf_lr = GridSearchCV(lr_model, param_grid = parameters, refit = True, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 04: Learning courve\n",
    "¿que sucede si probamos distintos tamaños de train set? ¿como se modificara el accuracy y AUC?\n",
    "Probar con trainset = <br>\n",
    "- 5%\n",
    "- 10%\n",
    "- 15%\n",
    "- 20%\n",
    "- 25%\n",
    "- ..%\n",
    "- ..%\n",
    "- 100%\n",
    "y comparar para KNN, LR y SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############\n",
    "######### CODIGO AQUI ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caba-2027-eda-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
