{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "__Universidad Tecnológica Nacional, Buenos Aires__<br/>\n",
    "__Ingeniería Industrial__<br/>\n",
    "__Cátedra de Ciencia de Datos - Curso I5521 - Turno Jueves noche__<br/>\n",
    "__Elaborado por: Lucas Mareque__<br/>\n",
    "__Editado por: Nicolas Aguirre__<br/>\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve , accuracy_score, auc, confusion_matrix\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "ENm61LzhGGYE",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Link: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "|Variable |\tDefinition |\tKey |\n",
    "| --- | --- | --- |\n",
    "|survival|\tSurvival|\t0 = No, 1 = Yes|\n",
    "|pclass|\tTicket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex|\tSex\t| |\n",
    "|Age|\tAge in years| |\t\n",
    "|sibsp|\t# of siblings / spouses aboard the Titanic| |\t\n",
    "|parch|\t# of parents / children aboard the Titanic| |\t\n",
    "|ticket|\tTicket number | |\t\n",
    "|fare|\tPassenger fare |\t|\n",
    "|cabin|\tCabin number\t| |\n",
    "|embarked|\tPort of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Objetivo: Predecir si un pasajero sobrevive al accidente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "root_path = '/path/to/clase_07/'\n",
    "titanic_df = pd.read_csv(root_path+\"titanic_train.csv\")\n",
    "# Observamos una parte de los datos\n",
    "titanic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Eliminamos columnas que no nos interesan\n",
    "titanic_df = titanic_df.drop(['PassengerId',\"Name\", \"Ticket\",\"Cabin\"],axis=1)\n",
    "total = titanic_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (titanic_df.isnull().sum()/titanic_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.head(6))\n",
    "list_a = ['S','Q','C']\n",
    "titanic_df.loc[~titanic_df['Embarked'].isin(list_a),:]\n",
    "# Lleno Embarked vacíos con \"S\"\n",
    "titanic_df['Embarked'].fillna('S', inplace = True)\n",
    "# chequeamos que todo esta con los NaN\n",
    "total = titanic_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (titanic_df.isnull().sum()/titanic_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea:**\n",
    "\n",
    "- Ver matriz de correlación. Determinar si hay variables que se puedan sacar\n",
    "- Distribución de pasajeros segun: clase y supervivencia , lugar de embarque y supervivencia, y precio y supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definimos las variables de entrenamiento y objetivo.\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']\n",
    "target = ['Survived']\n",
    "# Generamos X e Y\n",
    "X = titanic_df.loc[:,features]\n",
    "Y = titanic_df.loc[:,target]\n",
    "\n",
    "# Spliteamos Train y test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cantidad de valores nulos\n",
    "titanic_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reemplazamos los valores nulos de la columna Age por la media de los valores\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputer.fit(X_train[[\"Age\"]])\n",
    "X_train[\"Age\"] = imputer.transform(X_train[[\"Age\"]])\n",
    "X_test[\"Age\"] = imputer.transform(X_test[[\"Age\"]]) \n",
    "\n",
    "print(\"Media calculada:\", imputer.statistics_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Escalamos las variables numericos\n",
    "cols = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "scaler = StandardScaler()\n",
    "X_train[cols] = scaler.fit_transform(X_train[cols])\n",
    "X_test[[\"Age\", \"Fare\", \"SibSp\", \"Parch\"]] = scaler.transform(X_test[[\"Age\", \"Fare\", \"SibSp\", \"Parch\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.get_feature_names_out(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modificamos las variables categoricas\n",
    "cols = [\"Embarked\", \"Sex\", \"Pclass\"]\n",
    "encoder = OneHotEncoder(handle_unknown=\"error\",sparse_output=False)\n",
    "\n",
    "# Ajustar y transformar X_train\n",
    "X_train_encoded = encoder.fit_transform(X_train[cols])\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(cols), index=X_train.index)\n",
    "\n",
    "# Transformar X_test\n",
    "X_test_encoded = encoder.transform(X_test[cols])\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(cols), index=X_test.index)\n",
    "\n",
    "# Dropear las columnas originales\n",
    "X_train = X_train.drop(columns=cols)\n",
    "X_test = X_test.drop(columns=cols)\n",
    "\n",
    "# Concatenar las columnas codificadas\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vamos a entrenar un Random Forest, que consiste en un conjunto de árboles de decisión. Cada árbol realiza una predicción de manera independiente, y el resultado final se determina a partir del voto mayoritario entre todos los árboles:\n",
    "\n",
    "![](https://www.researchgate.net/publication/354354484/figure/fig4/AS:1080214163595269@1634554534720/Illustration-of-random-forest-trees.jpg)\n",
    "\n",
    "Contamos con diferentes hiperparametros, los analizados en este ejercicio son los siguientes:\n",
    "\n",
    "- **n_estimators**: cantidad de arboles de decisión que tendrá el random forest.\n",
    "- **max_depth**: número de niveles desde la raíz hasta la hoja más profunda.\n",
    "- **criterion**:  mientras mas cercano sea a 0, más puro será el nodo ( todas las muestras de la misma clase)\n",
    "    1. **Indice de Gini**: $Gini = 1 - \\sum_{i=1}^{K} p_i^2$.  \n",
    "   \n",
    "    2. **Entropía**: $Entropy = - \\sum_{i=1}^{K} p_i \\log_2(p_i)$ \n",
    "    \n",
    "    \n",
    "- **min_samples_leaf**: número mínimo de muestras que debe tener una hoja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  \n",
    "    'max_depth': [5, 10, 15],  \n",
    "    'min_samples_leaf': [1, 4, 6]   \n",
    "}\n",
    "CV_tree = GridSearchCV(estimator=tree,param_grid=param_grid,cv=5)\n",
    "CV_tree.fit(X_train, Y_train)\n",
    "print(\"Mejores hiperparámetros:\", CV_tree.best_params_)\n",
    "print(\"Mejor score en validación cruzada:\", CV_tree.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = CV_tree.best_estimator_.predict(X_test)\n",
    "print(\"\\nAccuracy en test:\", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(40,20))\n",
    "best_tree = CV_tree.best_estimator_\n",
    "# Dibujar el árbol\n",
    "tree.plot_tree(best_tree, \n",
    "               feature_names=X_train.columns,  # si X_train es DataFrame\n",
    "               class_names=[str(c) for c in best_tree.classes_],\n",
    "               filled=True,   # colorea los nodos según la clase\n",
    "               rounded=True,\n",
    "               fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Realizamos un Grid Search para encontrar los hiperparametros\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth' : [5, 10, 15],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'min_samples_leaf': [1, 4, 6]\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, Y_train)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# entrenamos el modelo con los hiperparametros encontrados\n",
    "rfc1=RandomForestClassifier(random_state=42, n_estimators= 200, max_depth=15, criterion='gini',min_samples_leaf=4)\n",
    "rfc1.fit(X_train, Y_train)\n",
    "pred=rfc1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for Random Forest on CV data: \",accuracy_score(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute and plot AUC\n",
    "fpr1, tpr1, thresholds = roc_curve(Y_test.astype('int'), pred, drop_intermediate = False)\n",
    "auc_value = auc(fpr1, tpr1)\n",
    "print(\"El AUC es = \" + str(auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr1, tpr1, lw=2, alpha=0.8 , label = 'ROC curve', color = 'b')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='r', alpha=.8)\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.grid(False)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('ROC Curve',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "df_cm = pd.DataFrame(cm, index = ['No sobrevivió', 'Sobrevivió'], columns = ['No sobrevivió', \"Sobreviviente\"])\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.heatmap(df_cm, annot=True,fmt='g')\n",
    "plt.title('Confusion matrix',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cluster_clase03_fit_svm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
